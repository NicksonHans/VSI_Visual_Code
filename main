import cv2
import tkinter as tk
from tkinter import Label, Button
from PIL import Image, ImageTk
from deepface import DeepFace
import mediapipe as mp
import numpy as np

# ------------------- Hand Gesture Recognition -------------------
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

hand_gesture_labels = {
    'FIST': "Fist",
    'PALM': "Open Palm",
    'PEACE': "Peace",
    'THUMB': "Thumbs Up",
    'ONE': "One Finger",
    'THREE': "Three Fingers",
    'FOUR': "Four Fingers"
}

def recognize_hand_gesture(hand_landmarks):
    lm = hand_landmarks.landmark

    def dist(a, b):
        return np.linalg.norm(np.array([a.x - b.x, a.y - b.y]))

    wrist = lm[0]
    thumb_tip = lm[4]
    thumb_ip = lm[3]
    index_tip = lm[8]
    middle_tip = lm[12]
    ring_tip = lm[16]
    pinky_tip = lm[20]

    extended = [
        dist(index_tip, wrist) > 0.2,
        dist(middle_tip, wrist) > 0.2,
        dist(ring_tip, wrist) > 0.2,
        dist(pinky_tip, wrist) > 0.2
    ]
    count = sum(extended)

    thumb_extended = dist(thumb_tip, wrist) > dist(thumb_ip, wrist) + 0.03
    thumb_above_hand = thumb_tip.y < thumb_ip.y < wrist.y

    if all(extended) and thumb_extended:
        return 'PALM'
    elif not any(extended) and not thumb_extended:
        return 'FIST'
    elif extended[0] and extended[1] and not extended[2] and not extended[3]:
        return 'PEACE'
    elif thumb_extended and not any(extended) and thumb_above_hand:
        return 'THUMB'
    elif extended == [1, 0, 0, 0]:
        return 'ONE'
    elif extended == [1, 1, 1, 0]:
        return 'THREE'
    elif extended == [1, 1, 1, 1]:
        return 'FOUR'
    else:
        return 'UNKNOWN'


# ------------------- GUI Class -------------------
class App:
    def __init__(self, window):
        self.window = window
        self.window.title("Visual Recognition Interface")
        self.window.configure(bg="#e6f0ff")

        tk.Label(window, text="Facial Expression & Hand Gesture Recognition", font=("Helvetica", 16, "bold"),
                 bg="#e6f0ff", fg="#003366").pack(pady=10)

        self.label = Label(window, bg="#e6f0ff")
        self.label.pack()

        self.status_label = Label(window, text="Camera Off", font=("Arial", 12), bg="#e6f0ff", fg="gray")
        self.status_label.pack(pady=5)

        self.expression_label = Label(window, text="Expression: N/A", font=("Arial", 12), bg="#e6f0ff")
        self.expression_label.pack()

        self.gesture_label = Label(window, text="Hand Gesture: N/A", font=("Arial", 12), bg="#e6f0ff")
        self.gesture_label.pack()

        self.button_frame = tk.Frame(window, bg="#e6f0ff")
        self.button_frame.pack(pady=10)

        self.start_button = Button(self.button_frame, text="Start Camera", command=self.start_camera,
                                   bg="#4CAF50", fg="white", font=("Arial", 11), width=12)
        self.start_button.pack(side='left', padx=10)

        self.stop_button = Button(self.button_frame, text="Stop Camera", command=self.stop_camera,
                                  bg="#f44336", fg="white", font=("Arial", 11), width=12)
        self.stop_button.pack(side='right', padx=10)

        self.cap = None
        self.running = False

        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        self.hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5)

    def start_camera(self):
        if not self.running:
            self.cap = cv2.VideoCapture(0)
            self.running = True
            self.status_label.config(text="Camera On", fg="green")
            self.update_frame()

    def stop_camera(self):
        self.running = False
        self.status_label.config(text="Camera Off", fg="gray")
        self.label.config(image='')
        self.expression_label.config(text="Expression: N/A")
        self.gesture_label.config(text="Hand Gesture: N/A")
        if self.cap:
            self.cap.release()

    def update_frame(self):
        if self.running:
            ret, frame = self.cap.read()
            if not ret:
                return

            frame = cv2.flip(frame, 1)
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)
            expression_text = "N/A"

            for (x, y, w, h) in faces:
                face_roi = frame[y:y + h, x:x + w]
                try:
                    result = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)
                    expression_text = result[0]['dominant_emotion']
                except:
                    expression_text = "Unknown"
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                cv2.putText(frame, expression_text, (x + w + 10, y + 30), cv2.FONT_HERSHEY_SIMPLEX,
                            0.8, (0, 255, 0), 2, cv2.LINE_AA)

            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.hands.process(rgb_frame)
            gesture_text = "N/A"

            if results.multi_hand_landmarks:
                for hand_landmarks in results.multi_hand_landmarks:
                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                    gesture = recognize_hand_gesture(hand_landmarks)
                    gesture_text = hand_gesture_labels.get(gesture, "Unknown")

                    h, w, _ = frame.shape
                    cx = int(hand_landmarks.landmark[9].x * w)
                    cy = int(hand_landmarks.landmark[9].y * h)
                    cv2.putText(frame, gesture_text, (cx + 10, cy - 10), cv2.FONT_HERSHEY_SIMPLEX,
                                0.8, (255, 0, 0), 2, cv2.LINE_AA)
                    break

            self.expression_label.config(text=f"Expression: {expression_text}")
            self.gesture_label.config(text=f"Hand Gesture: {gesture_text}")

            img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            imgtk = ImageTk.PhotoImage(image=img)
            self.label.imgtk = imgtk
            self.label.configure(image=imgtk)

            self.window.after(10, self.update_frame)

# ------------------- Main -------------------
if __name__ == '__main__':
    root = tk.Tk()
    app = App(root)
    root.mainloop()
